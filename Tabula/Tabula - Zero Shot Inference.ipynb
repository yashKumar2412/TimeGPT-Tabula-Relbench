{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVTOG4v_7p1E",
        "outputId": "22dd0782-4ff4-4157-ff8f-6c12da5263f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.7/1.8 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -y\n",
        "!apt-get install python3.8 python3.8-distutils -y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BI0dOOPSsfu",
        "outputId": "83b8790f-bdc1-44f0-f3b7-3d934143c90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,110 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,164 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,615 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,453 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,425 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,701 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,487 kB]\n",
            "Fetched 20.4 MB in 5s (4,468 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8-lib2to3 python3.8-minimal\n",
            "Suggested packages:\n",
            "  python3.8-venv binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib mailcap mime-support python3.8 python3.8-distutils\n",
            "  python3.8-lib2to3 python3.8-minimal\n",
            "0 upgraded, 8 newly installed, 0 to remove and 55 not upgraded.\n",
            "Need to get 5,422 kB of archives.\n",
            "After this operation, 20.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 mailcap all 3.70+nmu1ubuntu1 [23.8 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 mime-support all 3.66 [3,696 B]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Fetched 5,422 kB in 2s (2,296 kB/s)\n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 123629 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package mailcap.\n",
            "Preparing to unpack .../2-mailcap_3.70+nmu1ubuntu1_all.deb ...\n",
            "Unpacking mailcap (3.70+nmu1ubuntu1) ...\n",
            "Selecting previously unselected package mime-support.\n",
            "Preparing to unpack .../3-mime-support_3.66_all.deb ...\n",
            "Unpacking mime-support (3.66) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../4-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../5-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "Preparing to unpack .../6-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../7-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up mailcap (3.70+nmu1ubuntu1) ...\n",
            "Setting up mime-support (3.66) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d--6foioSuAm",
        "outputId": "a0bcc736-ccc5-4bc3-e00d-d24c49b01344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0 2222k    0 16548    0     0   215k      0  0:00:10 --:--:--  0:00:10  215k\r100 2222k  100 2222k    0     0  18.4M      0 --:--:-- --:--:-- --:--:-- 18.3M\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.8 get-pip.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bdv89afwSy6C",
        "outputId": "605ab137-d30f-4228-c459-fad7b06462a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pip\n",
            "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting setuptools\n",
            "  Downloading setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting wheel\n",
            "  Downloading wheel-0.45.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
            "Downloading setuptools-75.3.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wheel-0.45.0-py3-none-any.whl (72 kB)\n",
            "Installing collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-24.3.1 setuptools-75.3.0 wheel-0.45.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkfLPyGI7Zu1",
        "outputId": "7ab48571-2840-49a4-947d-f575e80a10cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rtfm'...\n",
            "remote: Enumerating objects: 825, done.\u001b[K\n",
            "remote: Counting objects: 100% (192/192), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 825 (delta 148), reused 155 (delta 129), pack-reused 633 (from 1)\u001b[K\n",
            "Receiving objects: 100% (825/825), 19.12 MiB | 8.38 MiB/s, done.\n",
            "Resolving deltas: 100% (525/525), done.\n",
            "Updating files: 100% (178/178), done.\n",
            "/content/rtfm\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mlfoundations/rtfm.git\n",
        "%cd rtfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "6lzvMmOJ7jjn",
        "outputId": "a71fd0e4-660a-4a5a-aa35-f29e6ed4e61e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.5/789.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/jpgard/llama-recipes.git\n",
        "!pip install -q -e .\n",
        "!pip install -q --no-deps git+https://github.com/mlfoundations/tableshift.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ak_bLmzk7yxJ",
        "outputId": "b7fefd75-6213-4b7b-e3e0-e141b70bbbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for llama-recipes (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tableshift (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/rtfm\n",
        "!pip install -q -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4syw_3r73vu",
        "outputId": "7328e682-8f21-42d1-c644-1221c614667d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rtfm\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: Legacy editable install of rtfm==0.0 from file:///content/rtfm (setup.py develop) is deprecated. pip 25.0 will enforce this behaviour change. A possible replacement is to add a pyproject.toml or enable --use-pep517, and use setuptools >= 64. If the resulting installation is not behaving as expected, try using --config-settings editable_mode=compat. Please consult the setuptools documentation for more information. Discussion can be found at https://github.com/pypa/pip/issues/11457\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "id": "fqtUhIGM75T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd rtfm\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -q -e ."
      ],
      "metadata": {
        "id": "6z_ffn9J78Rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -q -y rtfm tabliblib"
      ],
      "metadata": {
        "id": "9cCjFsg17-rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/mlfoundations/tabliblib.git\n",
        "!pip install -q -e /content/rtfm"
      ],
      "metadata": {
        "id": "4fuB-qJc9eQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsCyVwSJ8EqI",
        "outputId": "653840b1-fc1e-409d-e124-d24af6e12712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -q -y nltk\n",
        "!pip install -q nltk"
      ],
      "metadata": {
        "id": "2LkVUkY4THnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.data.path.clear()\n",
        "nltk.data.path.append('/root/nltk_data')"
      ],
      "metadata": {
        "id": "nANi8eRJ8Gqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, LlamaForCausalLM, AutoConfig\n",
        "\n",
        "from rtfm.configs import TrainConfig, TokenizerConfig\n",
        "from rtfm.inference_utils import InferenceModel\n",
        "from rtfm.serialization.serializers import get_serializer\n",
        "from rtfm.tokenization.text import prepare_tokenizer"
      ],
      "metadata": {
        "id": "fnpz2hxUCirJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_config = TrainConfig(model_name=\"mlfoundations/tabula-8b\", context_length=8192)\n",
        "\n",
        "# If using a base llama model (not fine-tuned TabuLa),\n",
        "# make sure to set add_serializer_tokens=False\n",
        "# (because we do not want to use special tokens for\n",
        "# the base model which is not trained on them).\n",
        "tokenizer_config = TokenizerConfig()\n",
        "\n",
        "# Load the configuration\n",
        "config = AutoConfig.from_pretrained(train_config.model_name)\n",
        "\n",
        "# Set the torch_dtype to bfloat16 which matches TabuLa train/eval setup\n",
        "config.torch_dtype = 'bfloat16'\n",
        "\n",
        "model = LlamaForCausalLM.from_pretrained(\n",
        "    train_config.model_name, device_map=\"auto\", config=config)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(train_config.model_name)\n",
        "serializer = get_serializer(train_config)\n",
        "\n",
        "tokenizer, model = prepare_tokenizer(\n",
        "    model,\n",
        "    tokenizer=tokenizer,\n",
        "    pretrained_model_name_or_path=train_config.model_name,\n",
        "    model_max_length=train_config.context_length,\n",
        "    use_fast_tokenizer=tokenizer_config.use_fast_tokenizer,\n",
        "    serializer_tokens_embed_fn=tokenizer_config.serializer_tokens_embed_fn,\n",
        "    serializer_tokens=serializer.special_tokens\n",
        "    if tokenizer_config.add_serializer_tokens\n",
        "    else None,\n",
        ")\n",
        "\n",
        "inference_model = InferenceModel(model=model, tokenizer=tokenizer, serializer=serializer)"
      ],
      "metadata": {
        "id": "AVemxbBp9Z2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_examples = pd.DataFrame(\n",
        "    [\n",
        "        {\"location\": \"New York\", \"temperature\": 22, \"humidity\": 65, \"wind_speed\": 12, \"pressure\": 1012, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Partly Sunny\"},\n",
        "        {\"location\": \"Los Angeles\", \"temperature\": 26, \"humidity\": 60, \"wind_speed\": 7, \"pressure\": 1015,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Partly Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "        {\"location\": \"Chicago\", \"temperature\": 18, \"humidity\": 70, \"wind_speed\": 15, \"pressure\": 1008, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.1, \"visibility\": 8, \"weather_today\": \"Cloudy\"},\n",
        "        {\"location\": \"Houston\", \"temperature\": 30, \"humidity\": 80, \"wind_speed\": 10, \"pressure\": 1010, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Rain\", \"precipitation\": 0.5, \"visibility\": 7, \"weather_today\": \"Rain\"},\n",
        "        {\"location\": \"Phoenix\", \"temperature\": 35, \"humidity\": 20, \"wind_speed\": 5, \"pressure\": 1005, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "        {\"location\": \"Philadelphia\", \"temperature\": 24, \"humidity\": 75, \"wind_speed\": 14, \"pressure\": 1009,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.2, \"visibility\": 9,\n",
        "         \"weather_today\": \"Partly Cloudy\"},\n",
        "        {\"location\": \"San Antonio\", \"temperature\": 28, \"humidity\": 68, \"wind_speed\": 11, \"pressure\": 1011,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Rain\", \"precipitation\": 0.4, \"visibility\": 8, \"weather_today\": \"Rain\"},\n",
        "        {\"location\": \"San Diego\", \"temperature\": 22, \"humidity\": 65, \"wind_speed\": 10, \"pressure\": 1014,\n",
        "         \"month\": \"July\", \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Partly Sunny\"},\n",
        "        {\"location\": \"Dallas\", \"temperature\": 27, \"humidity\": 72, \"wind_speed\": 9, \"pressure\": 1007, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Partly Cloudy\", \"precipitation\": 0.3, \"visibility\": 9, \"weather_today\": \"Cloudy\"},\n",
        "    ]\n",
        ")\n",
        "target_example = pd.DataFrame(\n",
        "    [\n",
        "        {\"location\": \"San Jose\", \"temperature\": 23, \"humidity\": 55, \"wind_speed\": 8, \"pressure\": 1013, \"month\": \"July\",\n",
        "         \"weather_yesterday\": \"Sunny\", \"precipitation\": 0, \"visibility\": 10, \"weather_today\": \"Sunny\"},\n",
        "    ]\n",
        ")\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"weather_today\",\n",
        "    target_choices=[\"Sunny\", \"Partly Sunny\", \"Cloudy\", \"Partly Cloudy\", \"Rain\"],\n",
        "    labeled_examples=labeled_examples,\n",
        ")\n",
        "\n",
        "print(f\"Prediction for {target_example['location']} is: {output}\")"
      ],
      "metadata": {
        "id": "JkPbWzW69qmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from rtfm.serialization.serialization_utils import discretize_continuous_column\n",
        "\n",
        "examples = pd.DataFrame(\n",
        "    [\n",
        "    {\"location\": \"New York\", \"size_sqft\": 1200, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 10, \"lot_size_acres\": 0.15, \"garage\": True, \"price\": 850},\n",
        "    {\"location\": \"Los Angeles\", \"size_sqft\": 1500, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 8, \"lot_size_acres\": 0.25, \"garage\": True, \"price\": 950},\n",
        "    {\"location\": \"Chicago\", \"size_sqft\": 1300, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 15, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 700},\n",
        "    {\"location\": \"Houston\", \"size_sqft\": 1700, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 5, \"lot_size_acres\": 0.3, \"garage\": True, \"price\": 650},\n",
        "    {\"location\": \"Phoenix\", \"size_sqft\": 1600, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 7, \"lot_size_acres\": 0.25, \"garage\": True, \"price\": 750},\n",
        "    {\"location\": \"Philadelphia\", \"size_sqft\": 1400, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 12, \"lot_size_acres\": 0.18, \"garage\": False, \"price\": 600},\n",
        "    {\"location\": \"San Antonio\", \"size_sqft\": 1800, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 3, \"lot_size_acres\": 0.4, \"garage\": True, \"price\": 700},\n",
        "    {\"location\": \"San Diego\", \"size_sqft\": 1550, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 9, \"lot_size_acres\": 0.22, \"garage\": True, \"price\": 850},\n",
        "    {\"location\": \"Dallas\", \"size_sqft\": 1450, \"bedrooms\": 3, \"bathrooms\": 2, \"age\": 11, \"lot_size_acres\": 0.19, \"garage\": True, \"price\": 700},\n",
        "    {\"location\": \"San Jose\", \"size_sqft\": 1600, \"bedrooms\": 4, \"bathrooms\": 3, \"age\": 6, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 800},\n",
        "    {\"location\": \"Seattle\", \"size_sqft\": 1800, \"bedrooms\": 4, \"bathrooms\": 2, \"age\": 10, \"lot_size_acres\": 0.2, \"garage\": False, \"price\": 925},\n",
        "]\n",
        ")\n",
        "\n",
        "examples[\"price\"] = discretize_continuous_column(examples[\"price\"], num_buckets=4)\n",
        "target_choices = examples[\"price\"].unique().tolist()\n",
        "\n",
        "target_example = examples.iloc[[0]]\n",
        "labeled_examples = examples.iloc[1:]\n",
        "\n",
        "\n",
        "output = inference_model.predict(\n",
        "    target_example=target_example,\n",
        "    target_colname=\"price\",\n",
        "    target_choices=target_choices,\n",
        "    labeled_examples=labeled_examples,\n",
        ")\n",
        "\n",
        "print(f\"Prediction for {target_example['location']} is: {output}\")"
      ],
      "metadata": {
        "id": "-a2CZ0ib93QD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}